{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Image Classification - Azure ML SDK Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Fashion MNIST notebook we introduce how to take the models you have registered and versioned, deploy them to production and monitor them \n",
    "\n",
    "This code will show how Azure ML SDK can support your machine learning project with:\n",
    "* creating a training and scoring script for your model\n",
    "* creating a bespoke environment for your model to run in (libraries and packages to install)\n",
    "* setting up a container service to host your model\n",
    "* deploying your model to the cloud container service\n",
    "* retrieving the service scoring URL for your hosted model\n",
    "* sending test data to your hosted model to be scored and returned to compare for the accuracy of your model on your validation set\n",
    "\n",
    "This notebook is based off the great documentation tutorial here: [https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-deploy-models-with-aml](https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-deploy-models-with-aml?WT.mc_id=aisummit-github-amynic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  0.1.59\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load workspace and download registered model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/amyboyd/notebooks/deeplearningfashion/azureml-sdk-fashion/config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "os.stat_result(st_mode=33204, st_ino=5911128, st_dev=2081, st_nlink=1, st_uid=1003, st_gid=1003, st_size=2694024, st_atime=1540279071, st_mtime=1540279039, st_ctime=1540279039)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model=Model(ws, 'keras_dl_fashion')\n",
    "model.download(target_dir = '.')\n",
    "import os \n",
    "# verify the downloaded model file\n",
    "os.stat('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and format Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow Version is: 1.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "print(\"tensorflow Version is: \" + str(tf.__version__))\n",
    "\n",
    "import numpy as np\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras import backend as K\n",
    "print(os.environ['KERAS_BACKEND'])\n",
    "\n",
    "#Fashion MNIST Dataset CNN model development: https://github.com/zalandoresearch/fashion-mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import utils, losses, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#no. of classes\n",
    "num_classes = 10\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"Top\",          # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Jumper\",       # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Trainer\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = utils.to_categorical(y_test,  num_classes)\n",
    "\n",
    "#X_test = load_data('./data/test-images.gz', False) / 255.0\n",
    "#y_test = load_data('./data/test-labels.gz', True).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a score.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import keras as K\n",
    "from azureml.core.model import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    print(\"Python version: \" + str(sys.version) + \", keras version: \" + K.__version__)\n",
    "    print(\"Executing init() method...\")\n",
    "    model_path = Model.get_model_path('model.h5')\n",
    "    print(\"got model...\")\n",
    "    model = K.models.load_model(model_path)\n",
    "    print(\"loaded model...\")\n",
    "\n",
    "def run(raw_data):\n",
    "    print(\"Executing run(raw_data) method...\")\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    data = np.reshape(data, (30,28,28,1))\n",
    "    y_hat = model.predict(data)\n",
    "    print(\"Executed predictions...\")\n",
    "    return json.dumps(y_hat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bespoke environment to run your model in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"keras\")\n",
    "myenv.add_tensorflow_pip_package(core_type='cpu', version='1.11.0')\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "  - tensorflow==1.11.0\n",
      "- scikit-learn\n",
      "- keras\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"myenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a Container service to host your model in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"fashion-MNIST\",  \"method\" : \"keras\"}, \n",
    "                                               description='Deep Learning to classify fashion clothing items, using Keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model model.h5\n",
      "Creating image\n",
      "Image creation operation finished for image deployfashion-test-4:1, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running....................................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 2.49 s, sys: 111 ms, total: 2.6 s\n",
      "Wall time: 10min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  description = \"Deep Learning to classify fashion clothing items, using Keras\",\n",
    "                                                  tags = {\"data\": \"fashionmnist\", \"type\": \"classification\"}\n",
    "                                                 )\n",
    "\n",
    "service_name = 'deployfashion-test'\n",
    "service = Webservice.deploy(deployment_config = aciconfig,\n",
    "                                image_config = image_config,\n",
    "                                model_paths = ['model.h5'],\n",
    "                                name = service_name,\n",
    "                                workspace = ws)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://40.115.0.115:80/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your model by calling the hosted API with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct prediction for sample 0\n",
      "correct prediction for sample 1\n",
      "correct prediction for sample 2\n",
      "correct prediction for sample 3\n",
      "correct prediction for sample 4\n",
      "correct prediction for sample 5\n",
      "correct prediction for sample 6\n",
      "correct prediction for sample 7\n",
      "correct prediction for sample 8\n",
      "correct prediction for sample 9\n",
      "correct prediction for sample 10\n",
      "correct prediction for sample 11\n",
      "INCORRECT prediction for sample12\n",
      "correct prediction for sample 13\n",
      "correct prediction for sample 14\n",
      "correct prediction for sample 15\n",
      "correct prediction for sample 16\n",
      "correct prediction for sample 17\n",
      "correct prediction for sample 18\n",
      "INCORRECT prediction for sample19\n",
      "correct prediction for sample 20\n",
      "INCORRECT prediction for sample21\n",
      "correct prediction for sample 22\n",
      "correct prediction for sample 23\n",
      "correct prediction for sample 24\n",
      "correct prediction for sample 25\n",
      "correct prediction for sample 26\n",
      "correct prediction for sample 27\n",
      "correct prediction for sample 28\n",
      "correct prediction for sample 29\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "s = 30\n",
    "e = s + 30\n",
    "\n",
    "#sample_indices = (x_test[0:n])\n",
    "\n",
    "test_samples = json.dumps({\"data\": x_test[s:e].tolist()})\n",
    "test_samples = bytes(test_samples, encoding = 'utf8')\n",
    "\n",
    "test_labels = y_test[s:e]\n",
    "\n",
    "##testing input correct\n",
    "body = np.array(json.loads(test_samples)['data'])\n",
    "\n",
    "# predict using the deployed model\n",
    "result = json.loads(service.run(input_data=test_samples))\n",
    "\n",
    "for i in range(0, len(result)):\n",
    "    indice_prediction = np.argmax(result[i])\n",
    "    indice_label = np.argmax(test_labels[i])\n",
    "    if indice_prediction == indice_label:\n",
    "        print(\"correct prediction for sample \" + str(i))\n",
    "    else:\n",
    "        print(\"INCORRECT prediction for sample\" + str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [myenv]",
   "language": "python",
   "name": "Python [myenv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
